{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c094809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e77c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5688d2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8dec4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 31)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92d8d265",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18804\\262839564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Class\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Binary Class Distribution'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Class\", data=data)\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Binary Class Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b833d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,1:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83b0eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d27148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6be5309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " 0    0.988655\n",
      "1    0.011345\n",
      "Name: Class, dtype: float64\n",
      "Testing set class distribution:\n",
      " 0    0.987097\n",
      "1    0.012903\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_class_dist = y_train.value_counts(normalize=True)\n",
    "test_class_dist = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Training set class distribution:\\n\", train_class_dist)\n",
    "print(\"Testing set class distribution:\\n\", test_class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6685eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 28)\n",
      "(617,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d388bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train_resampled) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b612a186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "160d5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0842c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.58      0.73       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.58       155\n",
      "   macro avg       0.50      0.54      0.38       155\n",
      "weighted avg       0.98      0.58      0.72       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.45      0.62       153\n",
      "           1       0.01      0.50      0.02         2\n",
      "\n",
      "    accuracy                           0.45       155\n",
      "   macro avg       0.50      0.48      0.32       155\n",
      "weighted avg       0.97      0.45      0.61       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.55       155\n",
      "   macro avg       0.50      0.52      0.37       155\n",
      "weighted avg       0.98      0.55      0.70       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.51      0.67       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.51       155\n",
      "   macro avg       0.50      0.50      0.35       155\n",
      "weighted avg       0.97      0.51      0.66       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.59       155\n",
      "   macro avg       0.50      0.54      0.38       155\n",
      "weighted avg       0.98      0.59      0.73       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.59       155\n",
      "   macro avg       0.50      0.54      0.38       155\n",
      "weighted avg       0.98      0.59      0.73       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.56      0.71       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.55       155\n",
      "   macro avg       0.50      0.53      0.37       155\n",
      "weighted avg       0.98      0.55      0.70       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.58      0.73       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.50      0.54      0.38       155\n",
      "weighted avg       0.98      0.57      0.72       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.50      0.53      0.38       155\n",
      "weighted avg       0.98      0.57      0.71       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.59       155\n",
      "   macro avg       0.50      0.54      0.38       155\n",
      "weighted avg       0.98      0.59      0.73       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66       153\n",
      "           1       0.01      0.50      0.02         2\n",
      "\n",
      "    accuracy                           0.49       155\n",
      "   macro avg       0.50      0.50      0.34       155\n",
      "weighted avg       0.97      0.49      0.65       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.53      0.69       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.53       155\n",
      "   macro avg       0.50      0.51      0.36       155\n",
      "weighted avg       0.98      0.53      0.68       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.60       155\n",
      "   macro avg       0.50      0.55      0.39       155\n",
      "weighted avg       0.98      0.60      0.74       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54       153\n",
      "           1       0.02      1.00      0.04         2\n",
      "\n",
      "    accuracy                           0.37       155\n",
      "   macro avg       0.51      0.68      0.29       155\n",
      "weighted avg       0.99      0.37      0.53       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53       153\n",
      "           1       0.02      1.00      0.04         2\n",
      "\n",
      "    accuracy                           0.37       155\n",
      "   macro avg       0.51      0.68      0.28       155\n",
      "weighted avg       0.99      0.37      0.52       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.50      0.53      0.38       155\n",
      "weighted avg       0.98      0.57      0.71       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.50      0.53      0.38       155\n",
      "weighted avg       0.98      0.57      0.71       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74       153\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.59       155\n",
      "   macro avg       0.50      0.55      0.39       155\n",
      "weighted avg       0.98      0.59      0.73       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.54      0.70       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.54       155\n",
      "   macro avg       0.50      0.52      0.36       155\n",
      "weighted avg       0.98      0.54      0.69       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.45      0.62       153\n",
      "           1       0.01      0.50      0.02         2\n",
      "\n",
      "    accuracy                           0.45       155\n",
      "   macro avg       0.50      0.48      0.32       155\n",
      "weighted avg       0.97      0.45      0.61       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66       153\n",
      "           1       0.01      0.50      0.02         2\n",
      "\n",
      "    accuracy                           0.49       155\n",
      "   macro avg       0.50      0.50      0.34       155\n",
      "weighted avg       0.97      0.49      0.65       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.45      0.62       153\n",
      "           1       0.01      0.50      0.02         2\n",
      "\n",
      "    accuracy                           0.45       155\n",
      "   macro avg       0.50      0.48      0.32       155\n",
      "weighted avg       0.97      0.45      0.61       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.56      0.71       153\n",
      "           1       0.01      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.55       155\n",
      "   macro avg       0.50      0.53      0.37       155\n",
      "weighted avg       0.98      0.55      0.70       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54       153\n",
      "           1       0.02      1.00      0.04         2\n",
      "\n",
      "    accuracy                           0.37       155\n",
      "   macro avg       0.51      0.68      0.29       155\n",
      "weighted avg       0.99      0.37      0.53       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54       153\n",
      "           1       0.02      1.00      0.04         2\n",
      "\n",
      "    accuracy                           0.37       155\n",
      "   macro avg       0.51      0.68      0.29       155\n",
      "weighted avg       0.99      0.37      0.53       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9866e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined sampling(SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7051c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       153\n",
      "           1       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.89       155\n",
      "   macro avg       0.53      0.70      0.52       155\n",
      "weighted avg       0.98      0.89      0.93       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92       153\n",
      "           1       0.05      0.50      0.08         2\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.52      0.68      0.50       155\n",
      "weighted avg       0.98      0.86      0.91       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       153\n",
      "           1       0.05      0.50      0.10         2\n",
      "\n",
      "    accuracy                           0.88       155\n",
      "   macro avg       0.52      0.69      0.51       155\n",
      "weighted avg       0.98      0.88      0.92       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       153\n",
      "           1       0.05      0.50      0.09         2\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.52      0.68      0.51       155\n",
      "weighted avg       0.98      0.86      0.92       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       153\n",
      "           1       0.05      0.50      0.09         2\n",
      "\n",
      "    accuracy                           0.87       155\n",
      "   macro avg       0.52      0.69      0.51       155\n",
      "weighted avg       0.98      0.87      0.92       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       153\n",
      "           1       0.08      0.50      0.13         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       153\n",
      "           1       0.04      0.50      0.07         2\n",
      "\n",
      "    accuracy                           0.84       155\n",
      "   macro avg       0.52      0.67      0.49       155\n",
      "weighted avg       0.98      0.84      0.90       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       153\n",
      "           1       0.04      0.50      0.08         2\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.52      0.67      0.50       155\n",
      "weighted avg       0.98      0.85      0.90       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.49      0.42      0.45       155\n",
      "weighted avg       0.97      0.83      0.90       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90       153\n",
      "           1       0.03      0.50      0.06         2\n",
      "\n",
      "    accuracy                           0.81       155\n",
      "   macro avg       0.51      0.66      0.48       155\n",
      "weighted avg       0.98      0.81      0.89       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       153\n",
      "           1       0.04      0.50      0.07         2\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.52      0.67      0.49       155\n",
      "weighted avg       0.98      0.83      0.90       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2a207f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN sampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce2e9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       153\n",
      "           1       0.05      0.50      0.10         2\n",
      "\n",
      "    accuracy                           0.88       155\n",
      "   macro avg       0.52      0.69      0.51       155\n",
      "weighted avg       0.98      0.88      0.92       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       153\n",
      "           1       0.08      0.50      0.13         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       153\n",
      "           1       0.06      0.50      0.10         2\n",
      "\n",
      "    accuracy                           0.88       155\n",
      "   macro avg       0.52      0.69      0.52       155\n",
      "weighted avg       0.98      0.88      0.93       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.47      0.48       155\n",
      "weighted avg       0.97      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.47      0.48       155\n",
      "weighted avg       0.97      0.92      0.95       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       153\n",
      "           1       0.08      0.50      0.13         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "464e0cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "Sample 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "Sample 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.49      0.49      0.49       155\n",
      "weighted avg       0.97      0.97      0.97       155\n",
      "\n",
      "Sample 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "Sample 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "eec = EasyEnsembleClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "# create 5 samples\n",
    "sample_size = len(X_train_resampled) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))\n",
    "\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    eec.fit(X_sample, y_sample)\n",
    "    y_pred = eec.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e2f4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.130\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.508\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.130\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.508\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.508\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.512\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.507\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.508\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        print(f\"\\t\\tPR AUC: {pr_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
